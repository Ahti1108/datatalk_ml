{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  seniority  home  time  age  marital  records  job  expenses  \\\n",
       "0       1          9     1    60   30        2        1    3        73   \n",
       "1       1         17     1    60   58        3        1    1        48   \n",
       "2       2         10     2    36   46        2        2    3        90   \n",
       "3       1          0     1    60   24        1        1    1        63   \n",
       "4       1          0     1    36   26        1        1    1        46   \n",
       "\n",
       "   income  assets  debt  amount  price  \n",
       "0     129       0     0     800    846  \n",
       "1     131       0     0    1000   1658  \n",
       "2     200    3000     0    2000   2985  \n",
       "3     182    2500     0     900   1325  \n",
       "4     107       0     0     310    910  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CreditScore.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority     int64\n",
       "home         object\n",
       "time          int64\n",
       "age           int64\n",
       "marital      object\n",
       "records      object\n",
       "job          object\n",
       "expenses      int64\n",
       "income        int64\n",
       "assets        int64\n",
       "debt          int64\n",
       "amount        int64\n",
       "price         int64\n",
       "default       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.default.values\n",
    "y_val = df_val.default.values\n",
    "y_test = df_test.default.values\n",
    "\n",
    "del df_train['default']\n",
    "del df_val['default']\n",
    "del df_test['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the `default` variable\n",
    "* Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g `-df_train['expenses']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variab* `le - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "* `seniority`\n",
    "* `time`\n",
    "* `income`\n",
    "* `debt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Use only: `['seniority', 'income', 'assets', 'records', 'job', 'home']`\n",
    "\n",
    "`LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "* 0.512\n",
    "* 0.612\n",
    "* 0.712\n",
    "* 0.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority     int64\n",
       "home         object\n",
       "time          int64\n",
       "age           int64\n",
       "marital      object\n",
       "records      object\n",
       "job          object\n",
       "expenses      int64\n",
       "income        int64\n",
       "assets        int64\n",
       "debt          int64\n",
       "amount        int64\n",
       "price         int64\n",
       "default       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['seniority', 'income', 'assets']\n",
    "categorical = ['job', 'records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train[numerical + categorical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631874298540965"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val[numerical + categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "status_dec = (y_pred >= 0.5)\n",
    "(y_val == status_dec).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pos = (y_val == 1)\n",
    "actual_neg = (y_val == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.5\n",
    "pred_pos = (y_pred >= t)\n",
    "pred_neg = (y_pred < t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = (pred_pos & actual_pos).sum()\n",
    "tn = (pred_neg & actual_neg).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (pred_pos & actual_neg).sum()\n",
    "fn = (pred_neg & actual_pos).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 145)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 579)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[579,  66],\n",
       "       [145, 101]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = np.array([\n",
    "    [tn, fp],\n",
    "    [fn, tp]\n",
    "])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65 , 0.074],\n",
       "       [0.163, 0.113]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(confusion_matrix / confusion_matrix.sum()).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977973151824541"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4105691056910569"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tp / (tp + fn)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6047904191616766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = tp / (tp + fp)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 0.276\n",
      "0.01 0.288\n",
      "0.02 0.302\n",
      "0.03 0.323\n",
      "0.04 0.347\n",
      "0.05 0.373\n",
      "0.06 0.400\n",
      "0.07 0.418\n",
      "0.08 0.441\n",
      "0.09 0.458\n",
      "0.10 0.485\n",
      "0.11 0.504\n",
      "0.12 0.524\n",
      "0.13 0.540\n",
      "0.14 0.556\n",
      "0.15 0.563\n",
      "0.16 0.582\n",
      "0.17 0.602\n",
      "0.18 0.611\n",
      "0.19 0.623\n",
      "0.20 0.639\n",
      "0.21 0.650\n",
      "0.22 0.666\n",
      "0.23 0.677\n",
      "0.24 0.695\n",
      "0.25 0.701\n",
      "0.26 0.709\n",
      "0.27 0.715\n",
      "0.28 0.717\n",
      "0.29 0.728\n",
      "0.30 0.738\n",
      "0.31 0.746\n",
      "0.32 0.751\n",
      "0.33 0.753\n",
      "0.34 0.754\n",
      "0.35 0.762\n",
      "0.36 0.767\n",
      "0.37 0.764\n",
      "0.38 0.771\n",
      "0.39 0.778\n",
      "0.40 0.779\n",
      "0.41 0.776\n",
      "0.42 0.777\n",
      "0.43 0.779\n",
      "0.44 0.776\n",
      "0.45 0.768\n",
      "0.46 0.772\n",
      "0.47 0.773\n",
      "0.48 0.769\n",
      "0.49 0.764\n",
      "0.50 0.763\n",
      "0.51 0.759\n",
      "0.52 0.761\n",
      "0.53 0.761\n",
      "0.54 0.763\n",
      "0.55 0.761\n",
      "0.56 0.758\n",
      "0.57 0.761\n",
      "0.58 0.762\n",
      "0.59 0.762\n",
      "0.60 0.760\n",
      "0.61 0.755\n",
      "0.62 0.755\n",
      "0.63 0.758\n",
      "0.64 0.750\n",
      "0.65 0.750\n",
      "0.66 0.750\n",
      "0.67 0.746\n",
      "0.68 0.744\n",
      "0.69 0.744\n",
      "0.70 0.742\n",
      "0.71 0.741\n",
      "0.72 0.741\n",
      "0.73 0.741\n",
      "0.74 0.741\n",
      "0.75 0.740\n",
      "0.76 0.740\n",
      "0.77 0.737\n",
      "0.78 0.735\n",
      "0.79 0.734\n",
      "0.80 0.733\n",
      "0.81 0.734\n",
      "0.82 0.734\n",
      "0.83 0.734\n",
      "0.84 0.734\n",
      "0.85 0.735\n",
      "0.86 0.734\n",
      "0.87 0.733\n",
      "0.88 0.731\n",
      "0.89 0.727\n",
      "0.90 0.724\n",
      "0.91 0.725\n",
      "0.92 0.724\n",
      "0.93 0.724\n",
      "0.94 0.724\n",
      "0.95 0.724\n",
      "0.96 0.724\n",
      "0.97 0.724\n",
      "0.98 0.724\n",
      "0.99 0.724\n",
      "1.00 0.724\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    score = accuracy_score(y_val, y_pred >= t)\n",
    "    print('%.2f %.3f' %(t, score))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    # evaluate actual_negative and actual_positive\n",
    "    # confusion table\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "    \n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "    \n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 246, 645, 0, 0),\n",
       " (0.01, 246, 634, 0, 11),\n",
       " (0.02, 244, 620, 2, 25),\n",
       " (0.03, 242, 599, 4, 46),\n",
       " (0.04, 240, 576, 6, 69),\n",
       " (0.05, 238, 551, 8, 94),\n",
       " (0.06, 236, 525, 10, 120),\n",
       " (0.07, 236, 509, 10, 136),\n",
       " (0.08, 235, 487, 11, 158),\n",
       " (0.09, 232, 469, 14, 176),\n",
       " (0.1, 232, 445, 14, 200),\n",
       " (0.11, 231, 427, 15, 218),\n",
       " (0.12, 230, 408, 16, 237),\n",
       " (0.13, 230, 394, 16, 251),\n",
       " (0.14, 229, 379, 17, 266),\n",
       " (0.15, 227, 370, 19, 275),\n",
       " (0.16, 224, 350, 22, 295),\n",
       " (0.17, 223, 332, 23, 313),\n",
       " (0.18, 219, 320, 27, 325),\n",
       " (0.19, 217, 307, 29, 338),\n",
       " (0.2, 215, 291, 31, 354),\n",
       " (0.21, 212, 278, 34, 367),\n",
       " (0.22, 210, 262, 36, 383),\n",
       " (0.23, 207, 249, 39, 396),\n",
       " (0.24, 207, 233, 39, 412),\n",
       " (0.25, 204, 224, 42, 421),\n",
       " (0.26, 200, 213, 46, 432),\n",
       " (0.27, 194, 202, 52, 443),\n",
       " (0.28, 190, 196, 56, 449),\n",
       " (0.29, 185, 181, 61, 464),\n",
       " (0.3, 181, 168, 65, 477),\n",
       " (0.31, 176, 156, 70, 489),\n",
       " (0.32, 174, 150, 72, 495),\n",
       " (0.33, 168, 142, 78, 503),\n",
       " (0.34, 166, 139, 80, 506),\n",
       " (0.35000000000000003, 164, 130, 82, 515),\n",
       " (0.36, 160, 122, 86, 523),\n",
       " (0.37, 157, 121, 89, 524),\n",
       " (0.38, 156, 114, 90, 531),\n",
       " (0.39, 155, 107, 91, 538),\n",
       " (0.4, 151, 102, 95, 543),\n",
       " (0.41000000000000003, 147, 101, 99, 544),\n",
       " (0.42, 144, 97, 102, 548),\n",
       " (0.43, 141, 92, 105, 553),\n",
       " (0.44, 136, 90, 110, 555),\n",
       " (0.45, 129, 90, 117, 555),\n",
       " (0.46, 125, 82, 121, 563),\n",
       " (0.47000000000000003, 121, 77, 125, 568),\n",
       " (0.48, 115, 75, 131, 570),\n",
       " (0.49, 107, 71, 139, 574),\n",
       " (0.5, 101, 66, 145, 579),\n",
       " (0.51, 96, 65, 150, 580),\n",
       " (0.52, 96, 63, 150, 582),\n",
       " (0.53, 93, 60, 153, 585),\n",
       " (0.54, 90, 55, 156, 590),\n",
       " (0.55, 86, 53, 160, 592),\n",
       " (0.56, 81, 51, 165, 594),\n",
       " (0.5700000000000001, 81, 48, 165, 597),\n",
       " (0.58, 78, 44, 168, 601),\n",
       " (0.59, 75, 41, 171, 604),\n",
       " (0.6, 70, 38, 176, 607),\n",
       " (0.61, 64, 36, 182, 609),\n",
       " (0.62, 61, 33, 185, 612),\n",
       " (0.63, 56, 26, 190, 619),\n",
       " (0.64, 46, 23, 200, 622),\n",
       " (0.65, 43, 20, 203, 625),\n",
       " (0.66, 41, 18, 205, 627),\n",
       " (0.67, 36, 16, 210, 629),\n",
       " (0.68, 34, 16, 212, 629),\n",
       " (0.6900000000000001, 31, 13, 215, 632),\n",
       " (0.7000000000000001, 29, 13, 217, 632),\n",
       " (0.71, 28, 13, 218, 632),\n",
       " (0.72, 27, 12, 219, 633),\n",
       " (0.73, 25, 10, 221, 635),\n",
       " (0.74, 24, 9, 222, 636),\n",
       " (0.75, 23, 9, 223, 636),\n",
       " (0.76, 21, 7, 225, 638),\n",
       " (0.77, 19, 7, 227, 638),\n",
       " (0.78, 17, 7, 229, 638),\n",
       " (0.79, 16, 7, 230, 638),\n",
       " (0.8, 15, 7, 231, 638),\n",
       " (0.81, 15, 6, 231, 639),\n",
       " (0.8200000000000001, 15, 6, 231, 639),\n",
       " (0.8300000000000001, 15, 6, 231, 639),\n",
       " (0.84, 13, 4, 233, 641),\n",
       " (0.85, 13, 3, 233, 642),\n",
       " (0.86, 11, 2, 235, 643),\n",
       " (0.87, 10, 2, 236, 643),\n",
       " (0.88, 7, 1, 239, 644),\n",
       " (0.89, 4, 1, 242, 644),\n",
       " (0.9, 1, 1, 245, 644),\n",
       " (0.91, 1, 0, 245, 645),\n",
       " (0.92, 0, 0, 246, 645),\n",
       " (0.93, 0, 0, 246, 645),\n",
       " (0.9400000000000001, 0, 0, 246, 645),\n",
       " (0.9500000000000001, 0, 0, 246, 645),\n",
       " (0.96, 0, 0, 246, 645),\n",
       " (0.97, 0, 0, 246, 645),\n",
       " (0.98, 0, 0, 246, 645),\n",
       " (0.99, 0, 0, 246, 645),\n",
       " (1.0, 0, 0, 246, 645)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>246</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>246</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>244</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>242</td>\n",
       "      <td>599</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>240</td>\n",
       "      <td>576</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp   fp  fn  tn\n",
       "0       0.00  246  645   0   0\n",
       "1       0.01  246  634   0  11\n",
       "2       0.02  244  620   2  25\n",
       "3       0.03  242  599   4  46\n",
       "4       0.04  240  576   6  69"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "df_scores = pd.DataFrame(scores, columns = columns)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>246</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>246</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.982946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>244</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.99187</td>\n",
       "      <td>0.961240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>242</td>\n",
       "      <td>599</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.98374</td>\n",
       "      <td>0.928682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>240</td>\n",
       "      <td>576</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.893023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp   fp  fn  tn      tpr       fpr\n",
       "0       0.00  246  645   0   0  1.00000  1.000000\n",
       "1       0.01  246  634   0  11  1.00000  0.982946\n",
       "2       0.02  244  620   2  25  0.99187  0.961240\n",
       "3       0.03  242  599   4  46  0.98374  0.928682\n",
       "4       0.04  240  576   6  69  0.97561  0.893023"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR')\n",
    "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "`F1 = 2 * P * R / (P + R)`\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "* 0.1\n",
    "* 0.3\n",
    "* 0.5\n",
    "* 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\njtol\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    # evaluate actual_negative and actual_positive\n",
    "    # confusion table\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "    \n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "    \n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    \n",
    "    f1 = (2 * p * r) / (p + r)\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 246, 645, 0, 0, 0.43271767810026385),\n",
       " (0.01, 246, 634, 0, 11, 0.4369449378330373),\n",
       " (0.02, 244, 620, 2, 25, 0.43963963963963965),\n",
       " (0.03, 242, 599, 4, 46, 0.4452621895124196),\n",
       " (0.04, 240, 576, 6, 69, 0.45197740112994345),\n",
       " (0.05, 238, 551, 8, 94, 0.4599033816425121),\n",
       " (0.06, 236, 525, 10, 120, 0.4687189672293942),\n",
       " (0.07, 236, 509, 10, 136, 0.4762865792129163),\n",
       " (0.08, 235, 487, 11, 158, 0.4855371900826447),\n",
       " (0.09, 232, 469, 14, 176, 0.4899683210137276),\n",
       " (0.1, 232, 445, 14, 200, 0.5027085590465872),\n",
       " (0.11, 231, 427, 15, 218, 0.5110619469026549),\n",
       " (0.12, 230, 408, 16, 237, 0.5203619909502263),\n",
       " (0.13, 230, 394, 16, 251, 0.5287356321839081),\n",
       " (0.14, 229, 379, 17, 266, 0.5362997658079625),\n",
       " (0.15, 227, 370, 19, 275, 0.5385527876631079),\n",
       " (0.16, 224, 350, 22, 295, 0.5463414634146342),\n",
       " (0.17, 223, 332, 23, 313, 0.5568039950062422),\n",
       " (0.18, 219, 320, 27, 325, 0.5579617834394904),\n",
       " (0.19, 217, 307, 29, 338, 0.5636363636363636),\n",
       " (0.2, 215, 291, 31, 354, 0.5718085106382979),\n",
       " (0.21, 212, 278, 34, 367, 0.5760869565217391),\n",
       " (0.22, 210, 262, 36, 383, 0.5849582172701949),\n",
       " (0.23, 207, 249, 39, 396, 0.5897435897435899),\n",
       " (0.24, 207, 233, 39, 412, 0.6034985422740524),\n",
       " (0.25, 204, 224, 42, 421, 0.6053412462908012),\n",
       " (0.26, 200, 213, 46, 432, 0.6069802731411229),\n",
       " (0.27, 194, 202, 52, 443, 0.604361370716511),\n",
       " (0.28, 190, 196, 56, 449, 0.6012658227848101),\n",
       " (0.29, 185, 181, 61, 464, 0.6045751633986928),\n",
       " (0.3, 181, 168, 65, 477, 0.6084033613445378),\n",
       " (0.31, 176, 156, 70, 489, 0.6089965397923875),\n",
       " (0.32, 174, 150, 72, 495, 0.6105263157894738),\n",
       " (0.33, 168, 142, 78, 503, 0.60431654676259),\n",
       " (0.34, 166, 139, 80, 506, 0.6025408348457351),\n",
       " (0.35000000000000003, 164, 130, 82, 515, 0.6074074074074073),\n",
       " (0.36, 160, 122, 86, 523, 0.6060606060606061),\n",
       " (0.37, 157, 121, 89, 524, 0.5992366412213741),\n",
       " (0.38, 156, 114, 90, 531, 0.6046511627906976),\n",
       " (0.39, 155, 107, 91, 538, 0.6102362204724411),\n",
       " (0.4, 151, 102, 95, 543, 0.6052104208416833),\n",
       " (0.41000000000000003, 147, 101, 99, 544, 0.5951417004048583),\n",
       " (0.42, 144, 97, 102, 548, 0.5913757700205339),\n",
       " (0.43, 141, 92, 105, 553, 0.5887265135699373),\n",
       " (0.44, 136, 90, 110, 555, 0.576271186440678),\n",
       " (0.45, 129, 90, 117, 555, 0.5548387096774193),\n",
       " (0.46, 125, 82, 121, 563, 0.5518763796909492),\n",
       " (0.47000000000000003, 121, 77, 125, 568, 0.545045045045045),\n",
       " (0.48, 115, 75, 131, 570, 0.5275229357798165),\n",
       " (0.49, 107, 71, 139, 574, 0.5047169811320754),\n",
       " (0.5, 101, 66, 145, 579, 0.4891041162227603),\n",
       " (0.51, 96, 65, 150, 580, 0.47174447174447176),\n",
       " (0.52, 96, 63, 150, 582, 0.4740740740740741),\n",
       " (0.53, 93, 60, 153, 585, 0.46616541353383456),\n",
       " (0.54, 90, 55, 156, 590, 0.4603580562659847),\n",
       " (0.55, 86, 53, 160, 592, 0.4467532467532468),\n",
       " (0.56, 81, 51, 165, 594, 0.4285714285714286),\n",
       " (0.5700000000000001, 81, 48, 165, 597, 0.43199999999999994),\n",
       " (0.58, 78, 44, 168, 601, 0.42391304347826086),\n",
       " (0.59, 75, 41, 171, 604, 0.4143646408839779),\n",
       " (0.6, 70, 38, 176, 607, 0.39548022598870053),\n",
       " (0.61, 64, 36, 182, 609, 0.369942196531792),\n",
       " (0.62, 61, 33, 185, 612, 0.3588235294117647),\n",
       " (0.63, 56, 26, 190, 619, 0.3414634146341463),\n",
       " (0.64, 46, 23, 200, 622, 0.292063492063492),\n",
       " (0.65, 43, 20, 203, 625, 0.2783171521035599),\n",
       " (0.66, 41, 18, 205, 627, 0.26885245901639343),\n",
       " (0.67, 36, 16, 210, 629, 0.24161073825503354),\n",
       " (0.68, 34, 16, 212, 629, 0.22972972972972974),\n",
       " (0.6900000000000001, 31, 13, 215, 632, 0.21379310344827587),\n",
       " (0.7000000000000001, 29, 13, 217, 632, 0.2013888888888889),\n",
       " (0.71, 28, 13, 218, 632, 0.1951219512195122),\n",
       " (0.72, 27, 12, 219, 633, 0.1894736842105263),\n",
       " (0.73, 25, 10, 221, 635, 0.1779359430604982),\n",
       " (0.74, 24, 9, 222, 636, 0.17204301075268819),\n",
       " (0.75, 23, 9, 223, 636, 0.16546762589928057),\n",
       " (0.76, 21, 7, 225, 638, 0.15328467153284672),\n",
       " (0.77, 19, 7, 227, 638, 0.13970588235294118),\n",
       " (0.78, 17, 7, 229, 638, 0.12592592592592594),\n",
       " (0.79, 16, 7, 230, 638, 0.11895910780669146),\n",
       " (0.8, 15, 7, 231, 638, 0.1119402985074627),\n",
       " (0.81, 15, 6, 231, 639, 0.11235955056179776),\n",
       " (0.8200000000000001, 15, 6, 231, 639, 0.11235955056179776),\n",
       " (0.8300000000000001, 15, 6, 231, 639, 0.11235955056179776),\n",
       " (0.84, 13, 4, 233, 641, 0.09885931558935362),\n",
       " (0.85, 13, 3, 233, 642, 0.09923664122137404),\n",
       " (0.86, 11, 2, 235, 643, 0.08494208494208495),\n",
       " (0.87, 10, 2, 236, 643, 0.07751937984496124),\n",
       " (0.88, 7, 1, 239, 644, 0.05511811023622047),\n",
       " (0.89, 4, 1, 242, 644, 0.03187250996015937),\n",
       " (0.9, 1, 1, 245, 644, 0.00806451612903226),\n",
       " (0.91, 1, 0, 245, 645, 0.008097165991902834),\n",
       " (0.92, 0, 0, 246, 645, nan),\n",
       " (0.93, 0, 0, 246, 645, nan),\n",
       " (0.9400000000000001, 0, 0, 246, 645, nan),\n",
       " (0.9500000000000001, 0, 0, 246, 645, nan),\n",
       " (0.96, 0, 0, 246, 645, nan),\n",
       " (0.97, 0, 0, 246, 645, nan),\n",
       " (0.98, 0, 0, 246, 645, nan),\n",
       " (0.99, 0, 0, 246, 645, nan),\n",
       " (1.0, 0, 0, 246, 645, nan)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>246</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>246</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.436945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>244</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.439640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>242</td>\n",
       "      <td>599</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.445262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>240</td>\n",
       "      <td>576</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>0.451977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp   fp  fn  tn        f1\n",
       "0       0.00  246  645   0   0  0.432718\n",
       "1       0.01  246  634   0  11  0.436945\n",
       "2       0.02  244  620   2  25  0.439640\n",
       "3       0.03  242  599   4  46  0.445262\n",
       "4       0.04  240  576   6  69  0.451977"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'f1']\n",
    "df_scores = pd.DataFrame(scores, columns = columns)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer is 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "`KFold(n_splits=5, shuffle=True, random_state=1)`\n",
    "\n",
    "\n",
    "* Iterate over different folds of df_full_train\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "* 0.001\n",
    "* 0.014\n",
    "* 0.09\n",
    "* 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, model = train(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    # create feature matrix\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(df_val, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = next(kfold.split(df_full_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_full_train.iloc[train_idx]\n",
    "df_val = df_full_train.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train = df_train.default.values\n",
    "    y_val = df_val.default.values\n",
    "    \n",
    "    dv, model = train(df_train, y_train)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800 +- 0.018\n"
     ]
    }
   ],
   "source": [
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize KFold with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "* 0.01\n",
    "* 0.1\n",
    "* 1\n",
    "* 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, model = train(df_train, y_train, C=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(df_val, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce08afc404c9439baeab464117a14760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001 0.763 +- 0.009\n",
      "C=0.01 0.799 +- 0.014\n",
      "C=0.1 0.803 +- 0.016\n",
      "C=0.5 0.802 +- 0.017\n",
      "C=1 0.803 +- 0.016\n",
      "C=5 0.803 +- 0.016\n",
      "C=10 0.802 +- 0.017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.001, 0.01, 0.1, 0.5, 1, 5, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.default.values\n",
    "        y_val = df_val.default.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
